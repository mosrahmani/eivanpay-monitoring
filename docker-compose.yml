# Docker Compose v2 format (version field is obsolete)
services:
  # Nginx Reverse Proxy - Production Access
  # Direct access on ports 80/443 for subdomain monitoring.eivanpay.com
  nginx:
    image: nginx:1.25-alpine
    container_name: monitoring-nginx
    restart: unless-stopped
    ports:
      - "8080:80"     # HTTP - Internal port (routed by host nginx)
      - "8445:443"    # HTTPS - Internal port (routed by host nginx) - changed from 8443 to avoid conflict with GitLab SSH
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/auth:/etc/nginx/auth:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - grafana
      - prometheus
      # - alertmanager  # Temporarily disabled
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    security_opt:
      - no-new-privileges:true
    labels:
      - "com.eivan-pay.service=monitoring"
      - "com.eivan-pay.component=nginx"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Prometheus - Metrics Collection
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    user: "nobody"
    # Expose port for debugging and internal access
    expose:
      - "9090"
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp
      - /var/run
    labels:
      - "com.eivan-pay.service=monitoring"
      - "com.eivan-pay.component=prometheus"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/rules:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=90d'  # Production: Longer retention
      - '--storage.tsdb.retention.size=100GB'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:9090/-/healthy || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Grafana - Visualization
  grafana:
    image: grafana/grafana:10.2.0
    container_name: grafana
    restart: unless-stopped
    user: "472"
    # Expose port for internal access
    expose:
      - "3000"
    security_opt:
      - no-new-privileges:true
    labels:
      - "com.eivan-pay.service=monitoring"
      - "com.eivan-pay.component=grafana"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=${GRAFANA_ROOT_URL:-https://monitoring.eivanpay.com/grafana/}
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
      # Disable anonymous access - require login
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_AUTH_BASIC_ENABLED=true
      - GF_AUTH_DISABLE_LOGIN_FORM=false
      - GF_SECURITY_DISABLE_GRAVATAR=true
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
      - GF_LOG_LEVEL=warn
      - GF_SECURITY_COOKIE_SECURE=true
      - GF_SECURITY_COOKIE_SAMESITE=strict
      - GF_SECURITY_STRICT_TRANSPORT_SECURITY=true
      - GF_SECURITY_STRICT_TRANSPORT_SECURITY_MAX_AGE_SECONDS=31536000
      - GF_SECURITY_STRICT_TRANSPORT_SECURITY_PRELOAD=true
      - GF_SECURITY_STRICT_TRANSPORT_SECURITY_SUBDOMAINS=true
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Node Exporter - System Metrics
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: node-exporter
    restart: unless-stopped
    # Security: Internal network only, no public exposure needed
    # Port exposed only for Prometheus scraping
    expose:
      - "9100"
    security_opt:
      - no-new-privileges:true
    labels:
      - "com.eivan-pay.service=monitoring"
      - "com.eivan-pay.component=node-exporter"
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9100/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3

  # cAdvisor - Container Metrics (OPTIONAL)
  # cAdvisor is optional and disabled by default
  # To enable: docker compose --profile cadvisor up -d
  cadvisor:
    profiles:
      - cadvisor  # Only starts with --profile cadvisor flag
    # Using Docker Hub (google/cadvisor)
    image: google/cadvisor:v0.47.0
    container_name: cadvisor
    restart: unless-stopped
    # Security: Internal network only
    expose:
      - "8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    # Note: cAdvisor requires privileged mode for container metrics
    # This is a known limitation, consider alternatives for production
    privileged: true
    devices:
      - /dev/kmsg
    security_opt:
      - apparmor:unconfined
    labels:
      - "com.eivan-pay.service=monitoring"
      - "com.eivan-pay.component=cadvisor"
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  # PostgreSQL Exporter - Database Metrics
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:v0.15.0
    container_name: postgres-exporter
    restart: unless-stopped
    # Security: Internal network only
    expose:
      - "9187"
    environment:
      # Use separate environment variables (no URL encoding needed)
      - DATA_SOURCE_USER=${POSTGRES_USER:-eivan_pay_user}
      - DATA_SOURCE_PASS=${POSTGRES_PASSWORD}
      - DATA_SOURCE_URI=${POSTGRES_HOST:-your_postgres_host}:${POSTGRES_PORT:-5432}/${POSTGRES_DB:-eivan_pay}?sslmode=disable
    security_opt:
      - no-new-privileges:true
    labels:
      - "com.eivan-pay.service=monitoring"
      - "com.eivan-pay.component=postgres-exporter"
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9187/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis Exporter - Cache Metrics (Temporarily disabled)
  # redis-exporter:
  #   image: oliver006/redis_exporter:v1.55.0
  #   container_name: redis-exporter
  #   restart: unless-stopped
  #   # Security: Internal network only
  #   expose:
  #     - "9121"
  #   environment:
  #     - REDIS_ADDR=${REDIS_HOST:-your_redis_host}:${REDIS_PORT:-6379}
  #     - REDIS_PASSWORD=${REDIS_PASSWORD}
  #   security_opt:
  #     - no-new-privileges:true
  #   labels:
  #     - "com.eivan-pay.service=monitoring"
  #     - "com.eivan-pay.component=redis-exporter"
  #   networks:
  #     - monitoring-network
  #   healthcheck:
  #     test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9121/metrics"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3

  # Alertmanager - Alert Management (Temporarily disabled)
  # alertmanager:
  #   image: prom/alertmanager:latest
  #   container_name: alertmanager
  #   restart: unless-stopped
  #   user: "nobody"
  #   # Production: No public ports, access via Nginx only
  #   ports: []
  #   security_opt:
  #     - no-new-privileges:true
  #   read_only: true
  #   tmpfs:
  #     - /tmp
  #     - /var/run
  #   labels:
  #     - "com.eivan-pay.service=monitoring"
  #     - "com.eivan-pay.component=alertmanager"
  #   env_file:
  #     - .env
  #   volumes:
  #     - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
  #     - ./alertmanager/templates:/etc/alertmanager/templates:ro
  #     - alertmanager_data:/alertmanager
  #   command:
  #     - '--config.file=/etc/alertmanager/alertmanager.yml'
  #     - '--storage.path=/alertmanager'
  #     - '--web.external-url=${ALERTMANAGER_EXTERNAL_URL:-https://monitoring.example.com/alertmanager}'
  #     - '--cluster.listen-address='
  #   depends_on:
  #     - prometheus
  #     - telegram-webhook
  #   networks:
  #     - monitoring-network
  #   healthcheck:
  #     test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 10s
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '0.5'
  #         memory: 512M
  #       reservations:
  #         cpus: '0.1'
  #         memory: 128M
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"

  # Telegram Webhook - Receives alerts and forwards to Telegram (Temporarily disabled)
  # telegram-webhook:
  #   build:
  #     context: ./alertmanager
  #     dockerfile: Dockerfile
  #   container_name: telegram-webhook
  #   restart: unless-stopped
  #   # User is set in Dockerfile (webhook:1000)
  #   # Security: Internal network only
  #   expose:
  #     - "8080"
  #     - "9091"  # Prometheus metrics port
  #   security_opt:
  #     - no-new-privileges:true
  #   read_only: true
  #   tmpfs:
  #     - /tmp
  #   environment:
  #     - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
  #     - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
  #     - PORT=8080
  #     - METRICS_PORT=9091
  #     - MAX_RETRIES=3
  #     - RATE_LIMIT_PER_MINUTE=20
  #   labels:
  #     - "com.eivan-pay.service=monitoring"
  #     - "com.eivan-pay.component=telegram-webhook"
  #   networks:
  #     - monitoring-network
  #   healthcheck:
  #     test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 5s
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '0.25'
  #         memory: 256M
  #       reservations:
  #         cpus: '0.05'
  #         memory: 64M
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"

networks:
  monitoring-network:
    driver: bridge
    name: eivan-pay-monitoring

volumes:
  prometheus_data:
    driver: local
    name: eivan-pay-prometheus-data
  grafana_data:
    driver: local
    name: eivan-pay-grafana-data
  alertmanager_data:
    driver: local
    name: eivan-pay-alertmanager-data
  nginx_logs:
    driver: local
    name: eivan-pay-monitoring-nginx-logs

